{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9aa99490-59c9-40c9-9108-08610c58c496",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W interface.cpp:47] Warning: Loading nvfuser library failed with: Error in dlopen: libnvfuser_codegen.so: cannot open shared object file: No such file or directory (function LoadingNvfuserLibrary)\n"
     ]
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "from glob import glob\n",
    "import os\n",
    "import random\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c18ba226-b918-406b-bb9d-e4338ed11efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import easyocr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38b5a56f-24b6-4b49-a7a0-82a1fd443e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## if training on custom data is needed ##\n",
    "#dataset = 'data/label_test2.yaml'\n",
    "#backbone = YOLO(\"yolov8s.pt\")  # load a pre-trained model (recommended for training)\n",
    "#results_train = backbone.train(data=dataset, epochs=120,name='label_test2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b5b93a4b-5fa4-4230-bfd7-d32833e85fba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/veglia/beegfs/yolov5/datasets/label_test2/video/VID20231103105624.mp4']\n"
     ]
    }
   ],
   "source": [
    "np_model = YOLO('/home/veglia/beegfs/yolov5/runs/detect/label_test22/weights/best.pt')\n",
    "\n",
    "videos = glob('data/video/*.mp4')\n",
    "print(videos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "78c311ee-3c13-43d8-b917-40b3c440c0c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING ⚠️ NMS time limit 0.550s exceeded\n",
      "0: 640x384 1 label, 216.4ms\n",
      "Speed: 4.9ms preprocess, 216.4ms inference, 897.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 label, 7.3ms\n",
      "Speed: 1.4ms preprocess, 7.3ms inference, 3.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 label, 8.2ms\n",
      "Speed: 3.6ms preprocess, 8.2ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 labels, 6.8ms\n",
      "Speed: 1.1ms preprocess, 6.8ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 label, 7.2ms\n",
      "Speed: 3.3ms preprocess, 7.2ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 label, 7.9ms\n",
      "Speed: 1.6ms preprocess, 7.9ms inference, 8.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 labels, 5.5ms\n",
      "Speed: 1.4ms preprocess, 5.5ms inference, 3.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 labels, 9.8ms\n",
      "Speed: 1.6ms preprocess, 9.8ms inference, 12.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 labels, 7.0ms\n",
      "Speed: 3.5ms preprocess, 7.0ms inference, 8.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 labels, 8.2ms\n",
      "Speed: 3.1ms preprocess, 8.2ms inference, 13.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 labels, 6.6ms\n",
      "Speed: 0.9ms preprocess, 6.6ms inference, 13.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 labels, 6.6ms\n",
      "Speed: 1.9ms preprocess, 6.6ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 labels, 11.4ms\n",
      "Speed: 2.1ms preprocess, 11.4ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 labels, 5.6ms\n",
      "Speed: 2.3ms preprocess, 5.6ms inference, 5.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 labels, 6.4ms\n",
      "Speed: 3.0ms preprocess, 6.4ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 labels, 6.7ms\n",
      "Speed: 2.0ms preprocess, 6.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 labels, 6.2ms\n",
      "Speed: 3.2ms preprocess, 6.2ms inference, 5.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 labels, 7.8ms\n",
      "Speed: 2.0ms preprocess, 7.8ms inference, 3.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 labels, 5.9ms\n",
      "Speed: 1.3ms preprocess, 5.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 labels, 6.4ms\n",
      "Speed: 2.8ms preprocess, 6.4ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 labels, 6.3ms\n",
      "Speed: 1.0ms preprocess, 6.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 labels, 6.0ms\n",
      "Speed: 1.1ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 labels, 6.4ms\n",
      "Speed: 2.8ms preprocess, 6.4ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 labels, 12.3ms\n",
      "Speed: 2.3ms preprocess, 12.3ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 labels, 9.1ms\n",
      "Speed: 2.8ms preprocess, 9.1ms inference, 14.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 labels, 10.0ms\n",
      "Speed: 1.5ms preprocess, 10.0ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 labels, 14.0ms\n",
      "Speed: 3.5ms preprocess, 14.0ms inference, 13.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 labels, 16.3ms\n",
      "Speed: 1.6ms preprocess, 16.3ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 labels, 11.0ms\n",
      "Speed: 2.8ms preprocess, 11.0ms inference, 12.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 labels, 8.9ms\n",
      "Speed: 3.5ms preprocess, 8.9ms inference, 34.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 labels, 12.4ms\n",
      "Speed: 2.0ms preprocess, 12.4ms inference, 38.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 6 labels, 9.6ms\n",
      "Speed: 1.4ms preprocess, 9.6ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 labels, 6.1ms\n",
      "Speed: 2.3ms preprocess, 6.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 labels, 6.1ms\n",
      "Speed: 1.1ms preprocess, 6.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 labels, 13.5ms\n",
      "Speed: 1.9ms preprocess, 13.5ms inference, 13.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 6 labels, 7.4ms\n",
      "Speed: 1.3ms preprocess, 7.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 labels, 6.5ms\n",
      "Speed: 1.4ms preprocess, 6.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 labels, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 labels, 7.0ms\n",
      "Speed: 2.9ms preprocess, 7.0ms inference, 8.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 labels, 13.1ms\n",
      "Speed: 2.9ms preprocess, 13.1ms inference, 12.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 labels, 6.6ms\n",
      "Speed: 1.3ms preprocess, 6.6ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 labels, 10.8ms\n",
      "Speed: 2.9ms preprocess, 10.8ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 labels, 10.2ms\n",
      "Speed: 1.7ms preprocess, 10.2ms inference, 12.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 labels, 14.8ms\n",
      "Speed: 3.0ms preprocess, 14.8ms inference, 7.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 labels, 11.6ms\n",
      "Speed: 3.3ms preprocess, 11.6ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 labels, 5.9ms\n",
      "Speed: 2.1ms preprocess, 5.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 labels, 9.4ms\n",
      "Speed: 1.7ms preprocess, 9.4ms inference, 29.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 labels, 8.6ms\n",
      "Speed: 4.6ms preprocess, 8.6ms inference, 14.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 labels, 9.2ms\n",
      "Speed: 5.3ms preprocess, 9.2ms inference, 34.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 labels, 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# read video by index\n",
    "video = cv.VideoCapture(videos[0])\n",
    "\n",
    "ret = True\n",
    "frame_number = -1\n",
    "vehicles = [0]\n",
    "\n",
    "# read the 50 first frames\n",
    "while ret:\n",
    "    frame_number += 1\n",
    "    ret, frame = video.read()\n",
    "\n",
    "    if ret and frame_number < 50:\n",
    "        \n",
    "        # label detector\n",
    "        detections = np_model.track(frame, persist=True)[0]\n",
    "        for detection in detections.boxes.data.tolist():\n",
    "            x1, y1, x2, y2, track_id, score, _ = detection\n",
    "            if score > 0.5:\n",
    "                vehicle_bounding_boxes = []\n",
    "                vehicle_bounding_boxes.append([x1, y1, x2, y2, track_id, score])\n",
    "                # process label\n",
    "                for license_plate in vehicle_bounding_boxes:\n",
    "                    plate_x1, plate_y1, plate_x2, plate_y2,_ ,plate_score = license_plate\n",
    "                    # crop plate from region of interest\n",
    "                    plate = frame[int(plate_y1):int(plate_y2), int(plate_x1):int(plate_x2)]\n",
    "                    # de-colorize\n",
    "                    gray = cv.cvtColor(cv.resize(plate,(0,0),fx=5,fy=5,interpolation=cv.INTER_CUBIC), cv.COLOR_BGR2GRAY)\n",
    "                    plate_crop = cv.resize(plate,(0,0),fx=5,fy=5,interpolation=cv.INTER_CUBIC)\n",
    "                    kernel = np.ones((1, 1), np.uint8)\n",
    "                    plate_crop = cv.dilate(plate_crop, kernel, iterations=1)\n",
    "                    plate_crop = cv.erode(plate_crop, kernel, iterations=1)\n",
    "                    plate_gray = cv.adaptiveThreshold(cv.medianBlur(gray, 7), 255, cv.ADAPTIVE_THRESH_GAUSSIAN_C,cv.THRESH_BINARY,11,2)\n",
    "                    # posterize\n",
    "                    cv.imwrite(str(track_id) + '_thresh.jpg', plate_crop)\n",
    "                    cv.imwrite(str(track_id) + '_gray.jpg', plate_gray)\n",
    "                        \n",
    "video.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "00efd9fe-ff90-491d-b579-e50aa4b11133",
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = easyocr.Reader(['en'], gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c73f785a-c73e-4253-84b8-2888d00bbd77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_license_plate(license_plate_crop):\n",
    "    detections = reader.readtext(license_plate_crop, allowlist ='0123456789')\n",
    "    for detection in detections:\n",
    "        bbox, text, score = detection\n",
    "\n",
    "        text = text.upper().replace(' ', '')\n",
    "        return text, score\n",
    "\n",
    "    return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d6a37165-110b-4fa6-b7bb-887bb004aa66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('17097', 0.2583249903759393)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_license_plate('test_gray.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "cef915bc-7f47-4373-806d-f8b9c13b786d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_csv(results, output_path):\n",
    "    \n",
    "    with open(output_path, 'w') as f:\n",
    "        f.write('{},{},{},{},{},{}\\n'.format(\n",
    "            'frame_number', 'track_id', 'label_bbox', 'label_bbox_score', 'read_label',\n",
    "            'text_score'))\n",
    "\n",
    "        for frame_number in results.keys():\n",
    "            for track_id in results[frame_number].keys():\n",
    "                if 'label' in results[frame_number][track_id].keys() and \\\n",
    "                   'read_label' in results[frame_number][track_id]['label'].keys():\n",
    "                    f.write('{},{},{},{},{},{}\\n'.format(\n",
    "                        frame_number,\n",
    "                        track_id,\n",
    "                        '[{} {} {} {}]'.format(\n",
    "                            results[frame_number][track_id]['label']['bbox'][0],\n",
    "                            results[frame_number][track_id]['label']['bbox'][1],\n",
    "                            results[frame_number][track_id]['label']['bbox'][2],\n",
    "                            results[frame_number][track_id]['label']['bbox'][3]\n",
    "                        ),\n",
    "                        results[frame_number][track_id]['label']['bbox_score'],\n",
    "                        results[frame_number][track_id]['label']['read_label'],\n",
    "                        results[frame_number][track_id]['label']['text_score'])\n",
    "                    )\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "84b6851a-257b-4104-8dbc-602fd9805c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "video = cv.VideoCapture(videos[0])\n",
    "ret = True\n",
    "frame_number = -1\n",
    "vehicles = [0]\n",
    "\n",
    "\n",
    "while ret:\n",
    "    frame_number += 1\n",
    "    ret, frame = video.read()\n",
    "\n",
    "    if ret and frame_number < 1400:\n",
    "        results[frame_number] = {}\n",
    "        # label detector\n",
    "        detections = np_model.track(frame, persist=True,verbose=False)[0]\n",
    "        for detection in detections.boxes.data.tolist():\n",
    "            if len(detection)<7:\n",
    "                continue\n",
    "            else:\n",
    "                x1, y1, x2, y2, track_id, score, _ = detection\n",
    "                if score > 0.5:\n",
    "                    vehicle_bounding_boxes = []\n",
    "                    vehicle_bounding_boxes.append([x1, y1, x2, y2, track_id, score])\n",
    "                    # process label\n",
    "                    for license_plate in vehicle_bounding_boxes:\n",
    "                        plate_x1, plate_y1, plate_x2, plate_y2,_ ,plate_score = license_plate\n",
    "                        # crop plate from region of interest\n",
    "                        plate = frame[int(plate_y1):int(plate_y2), int(plate_x1):int(plate_x2)]\n",
    "                        \n",
    "                        # enlarge and make digits clearer\n",
    "                        gray = cv.cvtColor(cv.resize(plate,(0,0),fx=5,fy=5,interpolation=cv.INTER_CUBIC), cv.COLOR_BGR2GRAY)\n",
    "                        plate_gray = cv.adaptiveThreshold(cv.medianBlur(gray, 7), 255, cv.ADAPTIVE_THRESH_GAUSSIAN_C,cv.THRESH_BINARY,11,2)\n",
    "    \n",
    "                        cv.imwrite('./outputs/images/'+str(frame_number) + '_gray.jpg', plate_gray)\n",
    "                        # OCR\n",
    "                        np_text, np_score = read_license_plate(plate_gray)\n",
    "    \n",
    "                        # if plate could be read write results\n",
    "                        if np_text is not None:\n",
    "                            results[frame_number][track_id] = {\n",
    "                                'label': {\n",
    "                                    'bbox': [plate_x1, plate_y1, plate_x2, plate_y2],\n",
    "                                    'bbox_score': plate_score,\n",
    "                                    'read_label': np_text,\n",
    "                                    'text_score': np_score}}\n",
    "\n",
    "write_csv(results, './results.csv')\n",
    "video.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "2f57fd04-7c4a-4e61-81fd-01a944babbca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_border(img, top_left, bottom_right, color=(0, 255, 0), thickness=6, line_length_x=200, line_length_y=200):\n",
    "    x1, y1 = top_left\n",
    "    x2, y2 = bottom_right\n",
    "\n",
    "    cv.line(img, (x1, y1), (x1, y1 + line_length_y), color, thickness)  #-- top-left\n",
    "    cv.line(img, (x1, y1), (x1 + line_length_x, y1), color, thickness)\n",
    "\n",
    "    cv.line(img, (x1, y2), (x1, y2 - line_length_y), color, thickness)  #-- bottom-left\n",
    "    cv.line(img, (x1, y2), (x1 + line_length_x, y2), color, thickness)\n",
    "\n",
    "    cv.line(img, (x2, y1), (x2 - line_length_x, y1), color, thickness)  #-- top-right\n",
    "    cv.line(img, (x2, y1), (x2, y1 + line_length_y), color, thickness)\n",
    "\n",
    "    cv.line(img, (x2, y2), (x2, y2 - line_length_y), color, thickness)  #-- bottom-right\n",
    "    cv.line(img, (x2, y2), (x2 - line_length_x, y2), color, thickness)\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "7715294a-8247-49bc-874b-f8ba27959568",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read video by index\n",
    "video = cv.VideoCapture(videos[0])\n",
    "\n",
    "# get video dims\n",
    "frame_width = int(video.get(3))\n",
    "frame_height = int(video.get(4))\n",
    "size = (frame_width, frame_height)\n",
    "\n",
    "# Define the codec and create VideoWriter object\n",
    "fourcc = cv.VideoWriter_fourcc(*'DIVX')\n",
    "out = cv.VideoWriter('./outputs/processed.avi', fourcc, 20.0, size)\n",
    "\n",
    "# reset video before you re-run cell below\n",
    "frame_number = -1\n",
    "video.set(cv.CAP_PROP_POS_FRAMES, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "989e72ec-c4ab-47c1-9f86-05c4a6b1822a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ret = True\n",
    "results = pd.read_csv('./results.csv')\n",
    "while ret:\n",
    "    ret, frame = video.read()\n",
    "    frame_number += 1\n",
    "    if ret:\n",
    "        df_ = results[results['frame_number'] == frame_number]\n",
    "        for index in range(len(df_)):\n",
    "            \n",
    "            # draw license plate\n",
    "            plate_x1, plate_y1, plate_x2, plate_y2 = ast.literal_eval(df_.iloc[index]['label_bbox'].replace('[ ', '[').replace('   ', ' ').replace('  ', ' ').replace(' ', ','))\n",
    "\n",
    "            # region of interest\n",
    "            cv.rectangle(frame, (int(plate_x1), int(plate_y1)), (int(plate_x2), int(plate_y2)), (0, 0, 255), 6)\n",
    "\n",
    "            # write detected number\n",
    "            (text_width, text_height), _ = cv.getTextSize(\n",
    "                str(df_.iloc[index]['read_label']),\n",
    "                cv.FONT_HERSHEY_SIMPLEX,\n",
    "                2,\n",
    "                6)\n",
    "\n",
    "            cv.putText(\n",
    "                frame,\n",
    "                str(df_.iloc[index]['read_label']),\n",
    "                (int((plate_x2 + plate_x1 - text_width)/2), int(plate_y1 - text_height)),\n",
    "                cv.FONT_HERSHEY_SIMPLEX,\n",
    "                2,\n",
    "                (0, 255, 0),\n",
    "                6\n",
    "            )\n",
    "\n",
    "        out.write(frame)\n",
    "        frame = cv.resize(frame, (1280, 720))\n",
    "\n",
    "out.release()\n",
    "video.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e5be1d03-7cf7-4bc2-a356-63256e447e1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = cv.imread('2.0_thresh.jpg')\n",
    "\n",
    "# convert the image to grayscale and blur it slightly\n",
    "gray = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n",
    "gray = cv.resize(gray,(0,0),fx=1,fy=1,interpolation=cv.INTER_CUBIC) \n",
    "plate_gray = cv.adaptiveThreshold(cv.medianBlur(gray, 7), 255, cv.ADAPTIVE_THRESH_GAUSSIAN_C,cv.THRESH_BINARY,11,2) \n",
    "\n",
    "cv.imwrite('test_gray.jpg', plate_gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "83b71208-a484-40f7-a71c-75c5028f9be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "33437045-939d-4cf8-b772-8f634e16a00a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1285.0,)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " results.iloc[40]['read_label'],"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa2b479-1bd0-4df5-afac-c1caf0a50344",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolo",
   "language": "python",
   "name": "yolo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
