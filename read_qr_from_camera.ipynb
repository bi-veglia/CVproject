{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9aa99490-59c9-40c9-9108-08610c58c496",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "from glob import glob\n",
    "from ultralytics import YOLO\n",
    "from pyzbar.pyzbar import decode\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38b5a56f-24b6-4b49-a7a0-82a1fd443e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## if training on custom data is needed ##\n",
    "#dataset = 'data/label_test2.yaml'\n",
    "#backbone = YOLO(\"yolov8s.pt\")  # load a pre-trained model (recommended for training)\n",
    "#results_train = backbone.train(data=dataset, epochs=120,name='label_test2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5b93a4b-5fa4-4230-bfd7-d32833e85fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "rl_model = YOLO('models/best.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qr_reader(qr_crop):\n",
    "    img=qr_crop\n",
    "    if img.shape[0]<80:\n",
    "        img=cv.resize(img, (0,0), fx=7, fy=7)\n",
    "    detection=decode(img)\n",
    "    if len(detection)>0:\n",
    "        text=detection[0].data.decode('utf-8')\n",
    "        return text\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m vid \u001b[38;5;241m=\u001b[39m \u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mVideoCapture\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m \n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#vid.set(3, 640)\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#vid.set(4, 480)\u001b[39;00m\n\u001b[0;32m      4\u001b[0m fourcc \u001b[38;5;241m=\u001b[39m cv\u001b[38;5;241m.\u001b[39mVideoWriter_fourcc(\u001b[38;5;241m*\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDIVX\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "vid = cv.VideoCapture(1) \n",
    "#vid.set(3, 640)\n",
    "#vid.set(4, 480)\n",
    "fourcc = cv.VideoWriter_fourcc(*'DIVX')\n",
    "out = cv.VideoWriter('./stream_detected2.avi', fourcc, 20.0, (640, 480))\n",
    "while(True): \n",
    "      \n",
    "    # Capture the video frame \n",
    "    # by frame \n",
    "    ret, img = vid.read() \n",
    "    frame_out=img\n",
    "    results = rl_model(img, stream=True)\n",
    "    for r in results:\n",
    "            boxes = r.boxes\n",
    "\n",
    "            for box in boxes:\n",
    "                x1, y1, x2, y2 = box.xyxy[0]\n",
    "                x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "\n",
    "                #plot box in video\n",
    "                cv.rectangle(img, (x1,y1),(x2,y2),(255,0,255),5)\n",
    "\n",
    "                #confidence\n",
    "                confidence = math.ceil((box.conf[0]*100))/100\n",
    "                if confidence >0.25:\n",
    "                    print('Confidence ---->', confidence)\n",
    "                    crop_label = img[y1:y2, x1:x2]\n",
    "                    qr_read=qr_reader(crop_label)\n",
    "\n",
    "                    if qr_read is not None:\n",
    "                        cv.rectangle(frame_out,(x1,y1),(x2,y2),(0,0,255),5)\n",
    "                        (text_width, text_height), _ = cv.getTextSize(qr_read, cv.FONT_HERSHEY_SIMPLEX, 2, 6)\n",
    "                        cv.putText(frame_out,qr_read,(int((x2+x1-text_width)/2), int(y1-text_height)),cv.FONT_HERSHEY_SIMPLEX,2, (0, 255, 0), 5)\n",
    "                        cv.putText(img,qr_read,(int((x2+x1-text_width)/2), int(y1-text_height)),cv.FONT_HERSHEY_SIMPLEX,2, (0, 255, 0), 5)\n",
    "    out.write(frame_out)\n",
    "\n",
    "    cv.imshow('Webcam',img)\n",
    "    if cv.waitKey(1)== ord('q'):\n",
    "         break\n",
    "       \n",
    "\n",
    "out.release()\n",
    "vid.release()\n",
    "cv.destroyAllWindows\n",
    "\n",
    "                        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
